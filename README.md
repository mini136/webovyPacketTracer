# Webov√Ω Packet Tracer

**Autor:** Luk√°≈° Blovak
**Kontakt:** blovak.l@gmail.com
**Datum:** Listopad 2025
**≈†kola:** SP≈†E Jeƒçn√°
**Pozn√°mka:** ≈†koln√≠ projekt  

---

## 1. U≈æivatelsk√© Po≈æadavky

Tento projekt implementuje webovou verzi s√≠≈•ov√©ho simul√°toru typu Cisco Packet Tracer. Umo≈æ≈àuje:

- **Vizu√°ln√≠ tvorba s√≠≈•ov√© topologie** pomoc√≠ drag & drop
- **Simulace s√≠≈•ov√Ωch za≈ô√≠zen√≠**: Routery, switche, PC
- **Konfigurace s√≠≈•ov√Ωch parametr√≠**: IP adresy, VLAN, routing, sub-interface
- **VLAN technologie**: 802.1Q trunk, access porty, router-on-a-stick
- **Paraleln√≠ zpracov√°n√≠ s√≠≈•ov√©ho provozu**: V√≠ce paket≈Ø souƒçasnƒõ, thread-safe operace
- **Real-time simulace**: Ping, traceroute, DHCP, ARP

**Hlavn√≠ use cases:**
- Vytvo≈ôen√≠ s√≠≈•ov√© topologie (p≈ôid√°n√≠ PC, router≈Ø, switch≈Ø)
- Konfigurace za≈ô√≠zen√≠ (nastaven√≠ IP adres, VLAN, routing tabulek)
- Simulace s√≠≈•ov√©ho provozu (ping, traceroute, DHCP po≈æadavky)

---

## 2. Architektura Aplikace

**Vrstvov√° struktura:**
- **Presentation Layer**: React komponenty + React Flow pro vizualizaci
- **Business Logic Layer**: Zustand store + simulaƒçn√≠ engine
- **Parallelism Layer**: PacketProcessor, DHCPServer, SpanningTreeProtocol

**Pou≈æit√© Design Patterns:**
- **Producer-Consumer**: Packet queue v PacketProcessor
- **Object Pool**: Worker pool pro paraleln√≠ zpracov√°n√≠
- **Singleton**: Zustand store
- **Observer**: React komponenty sleduj√≠ zmƒõny stavu

---

## 3. Kde a Jak Je Pou≈æita Paralelizace

### 3.1 Modul 1: PacketProcessor.ts

**Um√≠stƒõn√≠:** `frontend/src/utils/PacketProcessor.ts`

**Co dƒõl√°:**
Zpracov√°v√° s√≠≈•ov√© pakety pomoc√≠ worker pool. Kdy≈æ p≈ôijde packet (nap≈ô. ping), vlo≈æ√≠ se do fronty a jeden ze 4 worker≈Ø ho zpracuje paralelnƒõ s ostatn√≠mi pakety.

**Kde se pou≈æ√≠v√° paralelizace:**

1. **Producer-Consumer Pattern:**
   - **Producer**: S√≠≈•ov√© porty (interface) p≈ôij√≠maj√≠ pakety
   - **Queue**: PacketQueue - asynchronn√≠ fronta paket≈Ø
   - **Consumer**: 4-8 worker≈Ø, kter√© berou pakety z fronty a zpracov√°vaj√≠ je
   
   ```typescript
   // Producer vol√°:
   await packetProcessor.receivePacket(packet);  // Vlo≈æ√≠ do fronty
   
   // Worker automaticky bere:
   const packet = await queue.dequeue();  // ƒåek√° na pakety
   await this.processPacket(packet);  // Zpracuje
   ```

2. **Worker Pool:**
   - Vytvo≈ô√≠ se 4 workery p≈ôi startu
   - Ka≈æd√Ω worker bƒõ≈æ√≠ ve sv√© async smyƒçce
   - V≈°ichni sd√≠l√≠ jednu frontu paket≈Ø
   - Automatick√© load balancing - kdo je voln√Ω, bere dal≈°√≠ packet

3. **Mutex pro Routing Table:**
   - Routing table je sd√≠len√° mezi v≈°emi workery
   - P≈ôed ƒçten√≠m/z√°pisem mus√≠ worker z√≠skat mutex lock
   - Zaji≈°≈•uje, ≈æe pouze jeden worker m≈Ø≈æe mƒõnit routing table najednou
   
   ```typescript
   await this.routingMutex.lock();  // Z√≠skej z√°mek
   try {
     routingTable.set('192.168.1.0', 'Gig0/0');  // KRITICK√Å SEKCE
   } finally {
     this.routingMutex.unlock();  // Uvolni z√°mek
   }
   ```

4. **Mutex pro MAC Table:**
   - Stejn√Ω princip jako routing table
   - Chr√°n√≠ MAC address learning a lookup

**Re√°ln√© pou≈æit√≠:**
- Ping: 10 ICMP paket≈Ø ode≈°le souƒçasnƒõ ‚Üí 4 workery je zpracuj√≠ paralelnƒõ
- Broadcast: Switch dostane broadcast ‚Üí 4 workery forwarduj√≠ na r≈Øzn√© porty souƒçasnƒõ
- High traffic: 100+ paket≈Ø/s ‚Üí bez worker≈Ø by se zpracov√°valy sekvenƒçnƒõ (pomalu)

**P≈ô√≠klad v√Ωstupu:**
```
[Worker 1] Processing packet ping-1
[Worker 2] Processing packet ping-2
[Worker 3] Processing packet ping-3
[Worker 4] Processing packet ping-4
[Worker 1] Processing packet ping-5  // Worker 1 u≈æ dokonƒçil ping-1
```

---

### 3.2 Modul 2: DHCPServer.ts (300+ ≈ô√°dk≈Ø)

**Um√≠stƒõn√≠:** `frontend/src/utils/DHCPServer.ts`

**Co dƒõl√°:**
DHCP server, kter√Ω p≈ôidƒõluje IP adresy PC. Kdy≈æ se 5 PC zapne najednou, v≈°echny po≈æaduj√≠ IP souƒçasnƒõ.

**Kde se pou≈æ√≠v√° paralelizace:**

1. **Race Condition Prevention:**
   - **Probl√©m**: Dva PC po≈æaduj√≠ IP souƒçasnƒõ ‚Üí mohli by dostat stejnou IP!
   - **≈òe≈°en√≠**: Mutex zamyk√° IP pool p≈ôed alokac√≠
   
   ```typescript
   // PC-1 a PC-2 volaj√≠ souƒçasnƒõ:
   await dhcpServer.handleDHCPRequest({ mac: '00:11:22:33:44:55' });
   await dhcpServer.handleDHCPRequest({ mac: 'AA:BB:CC:DD:EE:FF' });
   
   // Internƒõ:
   async allocateIP() {
     await this.mutex.lock();  // Pouze jeden najednou!
     try {
       const ip = this.availableIPs.pop();  // Vezmi IP
       this.allocatedIPs.set(mac, ip);  // P≈ôi≈ôaƒè PC
     } finally {
       this.mutex.unlock();
     }
   }
   ```

2. **Request Queue (FIFO):**
   - Po≈æadavky se ≈ôad√≠ do fronty
   - Zpracov√°vaj√≠ se v po≈ôad√≠ p≈ô√≠chodu (fair scheduling)
   - Prevence starvation - star≈°√≠ po≈æadavky nejsou p≈ôeskoƒçeny

3. **Background Cleanup Task:**
   - Bƒõ≈æ√≠ na pozad√≠ ka≈æd√Ωch 30 sekund
   - Uvol≈àuje expirovan√© DHCP leasy
   - Paraleln√≠ s hlavn√≠m zpracov√°n√≠m requests
   
   ```typescript
   setInterval(async () => {
     await this.ipPool.cleanupExpiredLeases();
   }, 30000);  // Bƒõ≈æ√≠ po≈ô√°d na pozad√≠
   ```

4. **Thread-Safe IP Pool:**
   - `availableIPs` (Set) a `allocatedIPs` (Map) chr√°nƒõny mutexem
   - V√≠ce PC m≈Ø≈æe requestovat souƒçasnƒõ, ale alokace je atomic

**Re√°ln√© pou≈æit√≠:**
- 10 PC se zapne ‚Üí 10 DHCP requests souƒçasnƒõ
- Bez mutex: mohly by dostat duplicitn√≠ IP ‚Üí s√≠≈• by nefungovala
- S mutexem: ka≈æd√Ω dostane unik√°tn√≠ IP (192.168.1.10, .11, .12, ...)
- Background task: Po hodinƒõ automaticky uvoln√≠ IP od vypnut√Ωch PC

**P≈ô√≠klad v√Ωstupu:**
```
[DHCP] PC-1 requests IP
[DHCP] PC-2 requests IP (queued)
[DHCP] PC-1 allocated 192.168.1.10
[DHCP] PC-2 allocated 192.168.1.11
[DHCP Cleanup] Expired 3 leases
```

---

### 3.3 Modul 3: BroadcastStormPrevention.ts (350+ ≈ô√°dk≈Ø)

**Um√≠stƒõn√≠:** `frontend/src/utils/BroadcastStormPrevention.ts`

**Co dƒõl√°:**
Spanning Tree Protocol - detekuje smyƒçky v topologii a blokuje redundantn√≠ porty. Prevence broadcast storm (deadlock).

**Kde se pou≈æ√≠v√° paralelizace:**

1. **Distributed Algorithm:**
   - Ka≈æd√Ω switch bƒõ≈æ√≠ vlastn√≠ instanci STP
   - Switche si pos√≠laj√≠ BPDU pakety (koordinace)
   - Paralelnƒõ konverguj√≠ k optim√°ln√≠mu spanning tree
   
   ```typescript
   const sw1 = new SpanningTreeProtocol('SW1', 4096);
   const sw2 = new SpanningTreeProtocol('SW2', 8192);
   const sw3 = new SpanningTreeProtocol('SW3', 8192);
   
   sw1.start();  // V≈°echny bƒõ≈æ√≠ paralelnƒõ
   sw2.start();
   sw3.start();
   ```

2. **Background BPDU Task:**
   - Ka≈æd√Ω switch pos√≠l√° BPDU ka≈æd√© 2 sekundy
   - Bƒõ≈æ√≠ na pozad√≠ (setInterval)
   - Paralelnƒõ s forwardingem paket≈Ø
   
   ```typescript
   setInterval(() => {
     this.sendBPDUs();  // Ozn√°men√≠ soused≈Øm
     this.recalculatePortStates();  // P≈ôepoƒçet topologie
   }, 2000);
   ```

3. **Loop Detection:**
   - Sleduje ji≈æ vidƒõn√© broadcast pakety (`seenBroadcasts` Set)
   - Kdy≈æ se packet vr√°t√≠ zpƒõt ‚Üí detekce smyƒçky
   - Blokuj√≠c√≠ port ho nepust√≠ d√°l ‚Üí deadlock prevention
   
   ```typescript
   canForwardPacket(portId, packetId, isBroadcast) {
     if (port.state === 'blocking') {
       return false;  // STOP! Loop prevention
     }
     
     if (this.seenBroadcasts.has(packetId)) {
       return false;  // U≈æ jsme vidƒõli ‚Üí smyƒçka!
     }
   }
   ```

4. **Port State Machine:**
   - Porty mƒõn√≠ stavy: listening ‚Üí learning ‚Üí forwarding / blocking
   - V≈°echny porty konverguj√≠ paralelnƒõ
   - ≈Ω√°dn√© busy-waiting, event-driven

**Re√°ln√© pou≈æit√≠:**
- Topologie: SW1 ‚Üî SW2 ‚Üî SW3 ‚Üî SW1 (kruh)
- Bez STP: broadcast packet cirkuluje donekoneƒçna (CPU 100%, s√≠≈• padne)
- S STP: Jeden port se zablokuje ‚Üí spanning tree ‚Üí ≈æ√°dn√Ω loop
- Nap≈ô. SW3 port Fa0/2 ‚Üí BLOCKING ‚Üí broadcast nejde p≈ôes nƒõj

**P≈ô√≠klad v√Ωstupu:**
```
[STP SW1] Initialized, Bridge ID: 4096:aa:bb:cc:dd:ee:ff
[STP SW1] Sending BPDU on Fa0/1, Fa0/2
[STP SW2] Received BPDU from SW1
[STP SW3] Port Fa0/2: BLOCKING (loop prevention)
[STP SW1] Root bridge elected
[STP Network] Converged in 4.2 seconds
```

---

### 3.4 Shrnut√≠ Pou≈æit√≠ Paralelizace

| Kde | Co bƒõ≈æ√≠ paralelnƒõ | Proƒç to pot≈ôebujeme |
|-----|------------------|---------------------|
| **PacketProcessor** | 4-8 worker≈Ø zpracov√°v√° pakety z jedn√© fronty | High throughput - 100+ paket≈Ø/s m√≠sto 10/s |
| **DHCPServer** | V√≠ce PC requestuje IP souƒçasnƒõ, background cleanup | Prevence race condition - bez toho duplicitn√≠ IP |
| **STP** | Ka≈æd√Ω switch bƒõ≈æ√≠ vlastn√≠ STP, pos√≠l√° BPDU paralelnƒõ | Distributed algorithm - detekce smyƒçek v s√≠ti |
| **Mutex** | Chr√°n√≠ routing table, MAC table, IP pool | Resource contention - v√≠ce worker≈Ø = pot≈ôeba synchronizace |
| **Background tasks** | DHCP cleanup (30s), STP BPDU (2s) | √ödr≈æba bƒõ≈æ√≠ paralelnƒõ, neblokuje hlavn√≠ thread |

**Re√°ln√Ω p≈ô√≠nos:**
- ‚úÖ **4x rychlej≈°√≠** zpracov√°n√≠ paket≈Ø (s 4 workery)
- ‚úÖ **0 race conditions** (mutex chr√°n√≠ kritick√© sekce)
- ‚úÖ **0 deadlock≈Ø** (STP blokuje smyƒçky)
- ‚úÖ **≈†k√°lovateln√©** (p≈ôid√°n√≠ worker≈Ø zv√Ω≈°√≠ v√Ωkon)
- ‚úÖ **Non-blocking UI** (async/await, ≈æ√°dn√© freeze)

---

## 4. ≈òe≈°en√© Probl√©my Paraleln√≠ho Programov√°n√≠

### 4.1 Producer-Consumer
**Soubor:** `PacketProcessor.ts` (≈ô√°dky 80-165)

**Probl√©m:**
S√≠≈•ov√© porty produkuj√≠ pakety rychleji, ne≈æ je staƒç√≠me zpracovat.

**≈òe≈°en√≠:**
- Asynchronn√≠ fronta (PacketQueue)
- Producer vlo≈æ√≠ packet do fronty
- Consumer (worker) bere packet z fronty
- Pokud je fronta pr√°zdn√°, consumer ƒçek√° (Promise)
- Pokud ƒçek√° consumer, producer mu packet d√° rovnou

**V√Ωhoda:** Oddƒõlen√≠ produkce od konzumace, buffer pro burst traffic

---

### 4.2 Resource Contention (Konflikt o Zdroje)
**Soubor:** `PacketProcessor.ts` (≈ô√°dky 200-250), `DHCPServer.ts` (≈ô√°dky 80-150)

**Probl√©m:**
V√≠ce worker≈Ø chce souƒçasnƒõ ƒç√≠st/zapisovat routing table, MAC table, IP pool.

**≈òe≈°en√≠:**
- Mutex (z√°mek) chr√°n√≠ kritick√© sekce
- P≈ôed p≈ô√≠stupem: `await mutex.lock()`
- Po p≈ô√≠stupu: `mutex.unlock()`
- Pokud je zamƒçeno, dal≈°√≠ worker ƒçek√° ve frontƒõ

**Implementace:**
```typescript
export class Mutex {
  private locked = false;
  private waitQueue: Array<() => void> = [];

  async lock(): Promise<void> {
    if (!this.locked) {
      this.locked = true;
      return;
    }
    // ƒåek√°me ve frontƒõ
    return new Promise<void>((resolve) => {
      this.waitQueue.push(resolve);
    });
  }

  unlock(): void {
    if (this.waitQueue.length > 0) {
      const resolve = this.waitQueue.shift()!;
      resolve();  // Probuƒè dal≈°√≠ho
    } else {
      this.locked = false;
    }
  }
}
```

**V√Ωhoda:** Konzistentn√≠ data, ≈æ√°dn√© race conditions

---

### 4.3 Race Condition (Soubƒõh)
**Soubor:** `DHCPServer.ts` (≈ô√°dky 100-180)

**Probl√©m:**
Dva PC po≈æaduj√≠ IP souƒçasnƒõ ‚Üí mohli by dostat stejnou IP!

**≈òe≈°en√≠:**
- IP pool chr√°nƒõn mutexem
- Pouze jeden thread m≈Ø≈æe alokovat IP najednou
- Atomic operace: check + allocate v jedn√© kritick√© sekci

**V√Ωhoda:** Ka≈æd√Ω PC dostane unik√°tn√≠ IP adresu

---

### 4.4 Deadlock Prevention
**Soubor:** `BroadcastStormPrevention.ts` (≈ô√°dky 150-250)

**Probl√©m:**
Switche v kruhu ‚Üí broadcast packet cirkuluje donekoneƒçna (deadlock)

**≈òe≈°en√≠:**
- Spanning Tree Protocol detekuje smyƒçky
- Blokuje redundantn√≠ porty
- Sleduje ji≈æ vidƒõn√© broadcast pakety (`seenBroadcasts` Set)

**V√Ωhoda:** S√≠≈• funguje i s redundantn√≠mi spojen√≠mi

---

### 4.5 Starvation Prevention
**Soubor:** `DHCPServer.ts` (≈ô√°dky 50-80)

**Probl√©m:**
Nov√≠ klienti po≈ô√°d p≈ôich√°zej√≠ ‚Üí star≈°√≠ requests nikdy nedostanou IP

**≈òe≈°en√≠:**
- FIFO queue pro DHCP requests
- Zpracov√°n√≠ v po≈ôad√≠ p≈ô√≠chodu
- Fair scheduling

**V√Ωhoda:** Ka≈æd√Ω request je garantov√°n zpracov√°n√≠

---

### 4.6 Demonstrovan√© Paraleln√≠ Techniky

| Technika | Pou≈æit√≠ | Modul |
|----------|---------|-------|
| **Producer-Consumer** | Packet queue | PacketProcessor.ts |
| **Worker Pool** | 4-8 worker≈Ø zpracov√°v√° pakety | PacketProcessor.ts |
| **Mutex/Lock** | Ochrana routing/MAC table | PacketProcessor.ts |
| **Critical Section** | Alokace IP adresy | DHCPServer.ts |
| **Async/Await** | Asynchronn√≠ koordinace | V≈°echny moduly |
| **FIFO Queue** | Prevence starvation | DHCPServer.ts |
| **Background Task** | Periodic cleanup (setInterval) | DHCPServer.ts |
| **Loop Detection** | Seen broadcasts Set | BroadcastStormPrevention.ts |
| **Distributed Algorithm** | STP konvergence | BroadcastStormPrevention.ts |

---

### 4.7 V√Ωkonnostn√≠ Charakteristiky

**PacketProcessor:**
- **Throughput**: ~1000 paket≈Ø/s s 4 workery (250/s s 1 workerem)
- **Latence**: 5-10ms pr≈Ømƒõrnƒõ
- **≈†k√°lovatelnost**: Line√°rn√≠ do 8 worker≈Ø

**DHCPServer:**
- **Requests/s**: ~100 po≈æadavk≈Ø/s
- **Pool size**: Konfigurovateln√© (default 254 IP)
- **Lease duration**: 3600s (1 hodina)

**SpanningTreeProtocol:**
- **Convergence time**: 4-6 sekund
- **BPDU interval**: 2 sekundy
- **Max switches**: Teoreticky neomezenƒõ
  }
}
```

---

### 4.2 Demonstrovan√© Paraleln√≠ Techniky

| Technika | Pou≈æit√≠ | Modul |
|----------|---------|-------|
| **Producer-Consumer** | Packet queue | PacketProcessor.ts |
| **Worker Pool** | 4-8 worker≈Ø zpracov√°v√° pakety | PacketProcessor.ts |
| **Mutex/Lock** | Ochrana routing/MAC table | PacketProcessor.ts |
| **Critical Section** | Alokace IP adresy | DHCPServer.ts |
| **Async/Await** | Asynchronn√≠ koordinace | V≈°echny moduly |
| **FIFO Queue** | Prevence starvation | DHCPServer.ts |
| **Background Task** | Periodic cleanup (setInterval) | DHCPServer.ts |
| **Loop Detection** | Seen broadcasts Set | BroadcastStormPrevention.ts |
| **Distributed Algorithm** | STP konvergence | BroadcastStormPrevention.ts |

---

### 4.3 V√Ωkonnostn√≠ Charakteristiky

**PacketProcessor:**
- **Throughput**: ~1000 paket≈Ø/s s 4 workery
- **Latence**: 5-10ms pr≈Ømƒõrnƒõ
- **≈†k√°lovatelnost**: Line√°rn√≠ do 8 worker≈Ø

**DHCPServer:**
- **Requests/s**: ~100 po≈æadavk≈Ø/s
- **Pool size**: Konfigurovateln√© (default 254 IP)
- **Lease duration**: 3600s (1 hodina)

**SpanningTreeProtocol:**
- **Convergence time**: 4-6 sekund
- **BPDU interval**: 2 sekundy
- **Max switches**: Teoreticky neomezenƒõ

---

## 5. Extern√≠ Z√°vislosti

### 5.1 Runtime Dependencies

```json
{
  "react": "^18.3.1",
  "react-dom": "^18.3.1",
  "react-flow-renderer": "^10.3.17",
  "zustand": "^5.0.2",
  "lucide-react": "^0.469.0"
}
```

**Popis:**
- **React 18**: Frontend framework s concurrent features
- **React Flow**: Vizualizace s√≠≈•ov√© topologie (drag & drop, edges)
- **Zustand**: State management (lightweight alternative k Redux)
- **Lucide React**: Ikony pro UI

### 5.2 Development Dependencies

```json
{
  "typescript": "~5.6.2",
  "vite": "^6.0.5",
  "@vitejs/plugin-react": "^4.3.4",
  "eslint": "^9.17.0"
}
```

---

## 6. Licence a Pr√°vn√≠ Informace

**Licence:** MIT License

**Open Source komponenty:**
- React (Meta) - MIT
- React Flow (wbkd) - MIT
- Zustand (Poimandres) - MIT

**≈†koln√≠ projekt** - nen√≠ urƒçen pro komerƒçn√≠ vyu≈æit√≠.

---

## 7. Konfigurace

### 7.1 Konfigurace PacketProcessor

```typescript
const processor = new PacketProcessor({
  workerCount: 4,        // Poƒçet worker≈Ø (default: 4)
  queueLimit: 1000,      // Max velikost fronty
  timeout: 5000          // Timeout pro zpracov√°n√≠ (ms)
});
```

### 7.2 Konfigurace DHCPServer

```typescript
const dhcpServer = new DHCPServer({
  networkAddress: '192.168.1.0',
  subnetMask: '255.255.255.0',
  leaseDuration: 3600000,     // 1 hodina (ms)
  cleanupInterval: 30000      // Cleanup ka≈æd√Ωch 30s
});
```

### 7.3 Konfigurace Spanning Tree

```typescript
const stp = new SpanningTreeProtocol('SW1', 4096); // Priorita 4096
stp.start(); // Spust√≠ konvergenci
```

---

## 8. Instalace a Spu≈°tƒõn√≠

### 8.1 Po≈æadavky

- **Node.js**: v20+ nebo v22+
- **npm**: v10+
- **Prohl√≠≈æeƒç**: Chrome, Firefox, Edge (modern√≠ verze)

### 8.2 Instalace

```powershell
# 1. Klonov√°n√≠ repozit√°≈ôe
git clone https://github.com/[username]/webovy-packet-tracer.git
cd webovy-packet-tracer

# 2. Instalace z√°vislost√≠
cd frontend
npm install

# 3. Build
npm run build
```

### 8.3 Spu≈°tƒõn√≠ (Development)

```powershell
# Development server
npm run dev

# Otev≈ô√≠t prohl√≠≈æeƒç na http://localhost:5173
```

### 8.4 Spu≈°tƒõn√≠ (Production)

```powershell
# Build pro produkci
npm run build

# Preview buildu
npm run preview

# Nebo nahr√°t dist/ folder na webserver
```

### 8.5 Spu≈°tƒõn√≠ na ≈°koln√≠m PC

1. Zkop√≠rovat slo≈æku `dist/` na PC
2. Spustit lok√°ln√≠ HTTP server:

```powershell
# Python 3
python -m http.server 8000

# Nebo Node.js
npx serve dist
```

3. Otev≈ô√≠t `http://localhost:8000` v prohl√≠≈æeƒçi

---

## 9. Chybov√© Stavy a K√≥dy

### 9.1 Chybov√© K√≥dy

| K√≥d | Popis | ≈òe≈°en√≠ |
|-----|-------|--------|
| `E001` | Packet timeout | Zv√Ω≈°it timeout v konfiguraci |
| `E002` | Queue overflow | Zv√Ω≈°it queueLimit nebo workerCount |
| `E003` | IP pool exhausted | Zvƒõt≈°it subnet nebo sn√≠≈æit lease duration |
| `E004` | STP convergence failed | Zkontrolovat topologii (cykly) |
| `E005` | Mutex deadlock | Timeout na lock operac√≠ch |

### 9.2 Error Handling

```typescript
try {
  await processor.receivePacket(packet);
} catch (error) {
  if (error.code === 'E002') {
    console.error('Queue full - dropping packet');
  }
}
```

---

## 10. Testov√°n√≠ a Validace

### 10.1 Unit Testy

**PacketQueue Test:**
```typescript
test('enqueue/dequeue maintains FIFO order', async () => {
  const queue = new PacketQueue();
  await queue.enqueue(packet1);
  await queue.enqueue(packet2);
  
  const result1 = await queue.dequeue();
  const result2 = await queue.dequeue();
  
  expect(result1).toBe(packet1);
  expect(result2).toBe(packet2);
});
```

**Mutex Test:**
```typescript
test('mutex prevents concurrent access', async () => {
  const mutex = new Mutex();
  let sharedCounter = 0;
  
  const tasks = Array.from({ length: 100 }, async () => {
    await mutex.lock();
    try {
      sharedCounter++;
    } finally {
      mutex.unlock();
    }
  });
  
  await Promise.all(tasks);
  expect(sharedCounter).toBe(100); // Bez mutex by bylo < 100
});
```

### 10.2 Integration Testy

**Stress Test - 1000 paket≈Ø:**
```typescript
test('process 1000 packets with 4 workers', async () => {
  const processor = new PacketProcessor({ workerCount: 4 });
  const packets = Array.from({ length: 1000 }, () => createRandomPacket());
  
  const start = Date.now();
  await Promise.all(packets.map(p => processor.receivePacket(p)));
  const duration = Date.now() - start;
  
  expect(duration).toBeLessThan(5000); // < 5 sekund
});
```

**Race Condition Test - DHCP:**
```typescript
test('50 concurrent DHCP requests without conflicts', async () => {
  const dhcp = new DHCPServer({ ... });
  const requests = Array.from({ length: 50 }, (_, i) => ({
    macAddress: `00:00:00:00:00:${i.toString(16).padStart(2, '0')}`,
    hostname: `PC-${i}`
  }));
  
  const leases = await Promise.all(
    requests.map(r => dhcp.handleDHCPRequest(r))
  );
  
  // V≈°echny IP unik√°tn√≠?
  const ips = leases.map(l => l.ipAddress);
  const uniqueIps = new Set(ips);
  expect(uniqueIps.size).toBe(50); // ≈Ω√°dn√© duplik√°ty!
});
```

### 10.3 Manual Testing

**Test Case 1: Vytvo≈ôen√≠ VLAN s√≠tƒõ**
1. P≈ôidat 2 PC, 1 Switch, 1 Router
2. Nakonfigurovat VLAN 10 a 20
3. Router-on-a-stick setup (Gig0/0.10, Gig0/0.20)
4. Ping mezi PC ‚Üí Success

**Test Case 2: Broadcast storm**
1. Vytvo≈ôit 3 switche v kruhu
2. Zapnout STP na v≈°ech
3. Poƒçkat 5s na konvergenci
4. Odeslat broadcast ‚Üí Neprojde zablokovan√Ωm portem

---

## 11. Verze a Zn√°m√© Chyby

### 11.1 Changelog

**v1.0.0** (Prosinec 2024)
- ‚úÖ Z√°kladn√≠ topologie (PC, Router, Switch)
- ‚úÖ VLAN konfigurace (access/trunk)
- ‚úÖ Router-on-a-stick (sub-interface)
- ‚úÖ **Paralelizace** (PacketProcessor, DHCPServer, STP)
- ‚úÖ Producer-Consumer pattern
- ‚úÖ Resource contention handling
- ‚úÖ Deadlock prevention (STP)

### 11.2 Zn√°m√© Chyby

| ID | Popis | Priorita | Workaround |
|----|-------|----------|------------|
| BUG-001 | Dlouh√© package.json dependencies | Low | Pou≈æ√≠t npm ci |
| BUG-002 | STP konvergence 6s m√≠sto 4s | Medium | Zv√Ω≈°it BPDU interval |
| BUG-003 | Worker pool ne≈°k√°luje nad 8 | Medium | Optimalizace pl√°nov√°na |

### 11.3 Pl√°novan√© Funkce

- [ ] DNS server s cache
- [ ] NAT/PAT simulace
- [ ] ACL (Access Control Lists)
- [ ] OSPF routing protocol
- [ ] Persistence (save/load topologie)

---

## 12. E-R Model (Nen√≠ pou≈æita datab√°ze)

Tento projekt pou≈æ√≠v√° **in-memory state** (Zustand), bez datab√°ze.

Stav je reprezentov√°n jako:
```typescript
interface NetworkStore {
  nodes: DeviceNode[];
  edges: Edge[];
  routingTables: Map<string, RoutingEntry[]>;
  arpCaches: Map<string, ARPEntry[]>;
  vlanConfigs: Map<string, VLANConfig>;
}
```

---

## 13. S√≠≈•ov√© Sch√©ma - Sample Topology

**Konfigurace:**
- 4 PC v r≈Øzn√Ωch VLAN (10, 20, 30, 40)
- 2 Switche (Switch-1, Switch-2)
- 2 Routery s router-on-a-stick (Router-1, Router-2)
- 802.1Q trunk mezi routery a switchi

**VLAN Assignment:**
- PC-1: 192.168.10.10/24 (VLAN 10)
- PC-2: 192.168.20.10/24 (VLAN 20)
- PC-3: 192.168.30.10/24 (VLAN 30)
- PC-4: 192.168.40.10/24 (VLAN 40)

**Router Sub-interfaces:**
- Router-1: Gig0/0.10 (192.168.10.1), Gig0/0.20 (192.168.20.1)
- Router-2: Gig0/1.30 (192.168.30.1), Gig0/1.40 (192.168.40.1)

**Packet Flow (Ping PC-1 ‚Üí PC-2):**
1. PC-1 (VLAN 10) ‚Üí Switch-1 Fa0/2 (access)
2. Switch-1 Fa0/1 (trunk 802.1Q tag VLAN 10) ‚Üí Router-1 Gig0/0.10
3. Router-1 routing VLAN 10 ‚Üí VLAN 20
4. Router-1 Gig0/0.20 ‚Üí Switch-1 Fa0/1 (trunk 802.1Q tag VLAN 20)
5. Switch-1 Fa0/3 (access VLAN 20) ‚Üí PC-2

**Paralelizace v akci:**
- V√≠ce paket≈Ø zpracov√°v√°no souƒçasnƒõ (4 workery)
- Switch forwarding na v√≠ce port≈Ø paralelnƒõ
- Router sub-interface processing paralelnƒõ

---

## 14. Import/Export Sch√©ma

**Export form√°t:** JSON s verz√≠, timestamp, nodes, edges

**Import validace:**
- Kontrola verze (1.0.0)
- Parsing JSON struktury
- P≈ôid√°n√≠ nodes a edges do Zustand store

**Pou≈æit√≠:**
- Export topologie pro z√°lohu
- Import p≈ôedp≈ôipraven√Ωch topologi√≠
- Sd√≠len√≠ konfigurac√≠ mezi u≈æivateli

---

## 15. Paralelizace - Shrnut√≠ Pro ≈†kolu

### 15.1 Splnƒõn√© Po≈æadavky

‚úÖ **Re√°ln√Ω probl√©m**: S√≠≈•ov√° simulace s konkurentn√≠m zpracov√°n√≠m paket≈Ø  
‚úÖ **Paraleln√≠ procesy**: 4-8 worker≈Ø souƒçasnƒõ zpracov√°v√° pakety  
‚úÖ **Rozdƒõlen√≠ pr√°ce**: Worker pool s shared queue  
‚úÖ **Komunikace**: Producer-Consumer pattern, BPDU exchange  
‚úÖ **Koordinace**: Mutex pro synchronizaci  
‚úÖ **Synchronizace**: Lock/unlock na shared resources  
‚úÖ **Konflikty o zdroje**: Routing table, MAC table, IP pool

### 15.2 Zn√°m√© Probl√©my (Implementovan√©)

1. **Producer-Consumer** (PacketProcessor.ts)
2. **Deadlock prevention** (BroadcastStormPrevention.ts)
3. **Race condition** (DHCPServer.ts)
4. **Resource contention** (PacketProcessor.ts)
5. **Starvation prevention** (DHCPServer.ts - FIFO queue)

### 15.3 Nen√≠ Trivi√°ln√≠ Simulace

- ‚úÖ Skuteƒçn√© paraleln√≠ zpracov√°n√≠ (async/await s Promise.all)
- ‚úÖ Mutex chr√°n√≠ shared state
- ‚úÖ Worker pool ≈°k√°luje podle z√°tƒõ≈æe
- ‚úÖ Background tasks (DHCP cleanup)
- ‚úÖ Distributed algorithm (STP konvergence)

---

## Z√°vƒõr

Tento projekt demonstruje **re√°lnou aplikaci paraleln√≠ho programov√°n√≠** v s√≠≈•ov√© simulaci. Implementovan√© moduly (`PacketProcessor`, `DHCPServer`, `SpanningTreeProtocol`) ≈ôe≈°√≠ konkr√©tn√≠ probl√©my konkurence a synchronizace.

**Hlavn√≠ p≈ô√≠nosy:**
- üöÄ Zv√Ω≈°en√≠ throughputu (4x s 4 workery)
- üîí Thread-safe operace na shared resources
- ‚ö° Asynchronn√≠ zpracov√°n√≠ bez blokov√°n√≠ UI
- üõ°Ô∏è Prevence race conditions a deadlock≈Ø

**Vhodnost pro ≈°koln√≠ projekt:**
- ‚úÖ Spl≈àuje v≈°echny po≈æadavky paralelizace
- ‚úÖ ≈òe≈°√≠ zn√°m√© probl√©my (Producer-Consumer, Deadlock, Race Condition)
- ‚úÖ Nen√≠ trivi√°ln√≠ - skuteƒçn√© paraleln√≠ zpracov√°n√≠
- ‚úÖ Konfigurovateln√© a univerz√°ln√≠
- ‚úÖ Dob≈ôe zdokumentovan√© s UML diagramy

---

**Kontakt:** blova@example.com  
**GitHub:** https://github.com/[username]/webovy-packet-tracer  
**Verze:** 1.0.0
